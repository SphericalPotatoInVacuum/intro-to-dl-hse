{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OCfOAvvpXHaH"
   },
   "source": [
    "# –í–≤–µ–¥–µ–Ω–∏–µ –≤ –≥–ª—É–±–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ, –§–ö–ù –í–®–≠\n",
    "\n",
    "## –î–æ–º–∞—à–Ω–µ–µ –∑–∞–¥–∞–Ω–∏–µ 3. –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤.\n",
    "\n",
    "### –û–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è\n",
    "\n",
    "–î–∞—Ç–∞ –≤—ã–¥–∞—á–∏: 13.01.2022\n",
    "\n",
    "–ú—è–≥–∫–∏–π –¥–µ–¥–ª–∞–π–Ω: 23:59MSK 6.02.2022\n",
    "\n",
    "–ñ–µ—Å—Ç–∫–∏–π –¥–µ–¥–ª–∞–π–Ω: 23:59MSK 10.02.2022\n",
    "\n",
    "–û—Ü–µ–Ω–∫–∞ –ø–æ—Å–ª–µ —à—Ç—Ä–∞—Ñ–∞ –ø–æ—Å–ª–µ –º—è–≥–∫–æ–≥–æ –¥–µ–¥–ª–∞–π–Ω–∞ –≤—ã—á–∏—Å–ª—è–µ—Ç—Å—è –ø–æ —Ñ–æ—Ä–º—É–ª–µ $M_{penalty} = M_{full} \\cdot 0.85^{t/1440}$, –≥–¥–µ $M_{full}$ ‚Äî –ø–æ–ª–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∑–∞ —Ä–∞–±–æ—Ç—É –±–µ–∑ —É—á–µ—Ç–∞ —à—Ç—Ä–∞—Ñ–∞, –∞ $t$ ‚Äî –≤—Ä–µ–º—è –≤ –º–∏–Ω—É—Ç–∞—Ö, –ø—Ä–æ—à–µ–¥—à–µ–µ –ø–æ—Å–ª–µ –º—è–≥–∫–æ–≥–æ –¥–µ–¥–ª–∞–π–Ω–∞ (–æ–∫—Ä—É–≥–ª–µ–Ω–∏–µ –¥–æ –¥–≤—É—Ö —Ü–∏—Ñ—Ä –ø–æ—Å–ª–µ –∑–∞–ø—è—Ç–æ–π). –¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, —Å–ø—É—Å—Ç—è –ø–µ—Ä–≤—ã–µ —Å—É—Ç–∫–∏ –ø–æ—Å–ª–µ –º—è–≥–∫–æ–≥–æ –¥–µ–¥–ª–∞–π–Ω–∞ –≤—ã –Ω–µ –º–æ–∂–µ—Ç–µ –ø–æ–ª—É—á–∏—Ç—å –æ—Ü–µ–Ω–∫—É –≤—ã—à–µ 8.5, –∞ –µ—Å–ª–∏ —Å–¥–∞—Ç—å –ø–µ—Ä–µ–¥ —Å–∞–º—ã–º –∂–µ—Å—Ç–∫–∏–º –¥–µ–¥–ª–∞–π–Ω–æ–º, —Ç–æ –≤–∞—à –º–∞–∫—Å–∏–º—É–º ‚Äî 5.22 –±–∞–ª–ª–∞.\n",
    "\n",
    "### –û—Ü–µ–Ω–∏–≤–∞–Ω–∏–µ –∏ —à—Ç—Ä–∞—Ñ—ã\n",
    "\n",
    "–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –¥–æ–ø—É—Å—Ç–∏–º–∞—è –æ—Ü–µ–Ω–∫–∞ –∑–∞ —Ä–∞–±–æ—Ç—É ‚Äî 10 –±–∞–ª–ª–æ–≤. –°–¥–∞–≤–∞—Ç—å –∑–∞–¥–∞–Ω–∏–µ –ø–æ—Å–ª–µ —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ —Å—Ä–æ–∫–∞ —Å–¥–∞—á–∏ –Ω–µ–ª—å–∑—è.\n",
    "\n",
    "–ó–∞–¥–∞–Ω–∏–µ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ. ¬´–ü–æ—Ö–æ–∂–∏–µ¬ª —Ä–µ—à–µ–Ω–∏—è —Å—á–∏—Ç–∞—é—Ç—Å—è –ø–ª–∞–≥–∏–∞—Ç–æ–º –∏ –≤—Å–µ –∑–∞–¥–µ–π—Å—Ç–≤–æ–≤–∞–Ω–Ω—ã–µ —Å—Ç—É–¥–µ–Ω—Ç—ã (–≤ —Ç–æ–º —á–∏—Å–ª–µ —Ç–µ, —É –∫–æ–≥–æ —Å–ø–∏—Å–∞–ª–∏) –Ω–µ –º–æ–≥—É—Ç –ø–æ–ª—É—á–∏—Ç—å –∑–∞ –Ω–µ–≥–æ –±–æ–ª—å—à–µ 0 –±–∞–ª–ª–æ–≤. –ï—Å–ª–∏ –≤—ã –Ω–∞—à–ª–∏ —Ä–µ—à–µ–Ω–∏–µ –∫–∞–∫–æ–≥–æ-—Ç–æ –∏–∑ –∑–∞–¥–∞–Ω–∏–π (–∏–ª–∏ –µ–≥–æ —á–∞—Å—Ç—å) –≤ –æ—Ç–∫—Ä—ã—Ç–æ–º –∏—Å—Ç–æ—á–Ω–∏–∫–µ, –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å —Å—Å—ã–ª–∫—É –Ω–∞ —ç—Ç–æ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –±–ª–æ–∫–µ –≤ –∫–æ–Ω—Ü–µ –≤–∞—à–µ–π —Ä–∞–±–æ—Ç—ã (—Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –≤—ã –±—É–¥–µ—Ç–µ –Ω–µ –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–º, –∫—Ç–æ —ç—Ç–æ –Ω–∞—à–µ–ª, –ø–æ—ç—Ç–æ–º—É —á—Ç–æ–±—ã –∏—Å–∫–ª—é—á–∏—Ç—å –ø–æ–¥–æ–∑—Ä–µ–Ω–∏–µ –≤ –ø–ª–∞–≥–∏–∞—Ç–µ, –Ω–µ–æ–±—Ö–æ–¥–∏–º–∞ —Å—Å—ã–ª–∫–∞ –Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫).\n",
    "\n",
    "–ù–µ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–¥–∞ –º–æ–∂–µ—Ç –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ –æ—Ç—Ä–∞–∑–∏—Ç—å—Å—è –Ω–∞ –æ—Ü–µ–Ω–∫–µ. –¢–∞–∫–∂–µ –æ—Ü–µ–Ω–∫–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–Ω–∏–∂–µ–Ω–∞ –∑–∞ –ø–ª–æ—Ö–æ —á–∏—Ç–∞–µ–º—ã–π –∫–æ–¥ –∏ –ø–ª–æ—Ö–æ –æ—Ñ–æ—Ä–º–ª–µ–Ω–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏. –í—Å–µ –æ—Ç–≤–µ—Ç—ã –¥–æ–ª–∂–Ω—ã —Å–æ–ø—Ä–æ–≤–æ–∂–¥–∞—Ç—å—Å—è –∫–æ–¥–æ–º –∏–ª–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏ –æ —Ç–æ–º, –∫–∞–∫ –æ–Ω–∏ –±—ã–ª–∏ –ø–æ–ª—É—á–µ–Ω—ã.\n",
    "\n",
    "### –û –∑–∞–¥–∞–Ω–∏–∏\n",
    "\n",
    "–í –¥–∞–Ω–Ω–æ–º –¥–æ–º–∞—à–Ω–µ–º –∑–∞–¥–∞–Ω–∏–∏ –≤–∞–º –ø—Ä–µ–¥—Å—Ç–æ–∏—Ç –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫—É—é –æ—Ü–µ–Ω–∫—É –æ—Ç–µ–ª—è –ø–æ —Ç–µ–∫—Å—Ç—É –æ—Ç–∑—ã–≤–∞. –ù—É–∂–Ω–æ –æ–±—É—á–∏—Ç—å—Å—è –Ω–∞ –¥–∞–Ω–Ω—ã—Ö —Å –∫—ç–≥–≥–ª–∞ –∏ –∑–∞—Å–ª–∞—Ç—å –≤ [—Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏–µ](https://www.kaggle.com/t/3e8fa6cec6d048bf8e93fb72e441d88c) –ø—Ä–µ–¥–∏–∫—Ç. –ü–æ —Ç–æ–π –∂–µ —Å—Å—ã–ª–∫–µ –º–æ–∂–µ—Ç–µ —Å–∫–∞—á–∞—Ç—å –¥–∞–Ω–Ω—ã–µ.\n",
    "\n",
    "–ú—ã —Å–æ–±—Ä–∞–ª–∏ –¥–ª—è –≤–∞—Å –æ—Ç–∑—ã–≤—ã –ø–æ 1500 –æ—Ç–µ–ª—è–º –∏–∑ —Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ —Ä–∞–∑–Ω—ã—Ö —É–≥–æ–ª–∫–æ–≤ –º–∏—Ä–∞. –ß—Ç–æ —ç—Ç–æ –∑–∞ –æ—Ç–µ–ª–∏ - —Å–µ–∫—Ä–µ—Ç. –í–∞–º –¥–∞–Ω —Ç–µ–∫—Å—Ç –æ—Ç–∑—ã–≤–∞ –∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞ –æ—Ç–µ–ª—è. –í–∞—à–∞ –∑–∞–¥–∞—á–∞ - –Ω–∞—É—á–∏—Ç—å—Å—è –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å –æ—Ü–µ–Ω–∫—É –æ—Ç–µ–ª—è –ø–æ –æ—Ç–∑—ã–≤—É.\n",
    "\n",
    "–ì–ª–∞–≤–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞ - Mean Absolute Error (MAE). –í–æ –≤—Å–µ—Ö —á–∞—Å—Ç—è—Ö –¥–æ–º–∞—à–Ω–µ–π —Ä–∞–±–æ—Ç—ã –≤–∞–º –Ω—É–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ MAE –Ω–µ –ø—Ä–µ–≤—ã—à–∞—é—â–µ–µ 0.92 –Ω–∞ –ø—É–±–ª–∏—á–Ω–æ–º –ª–∏–¥–µ—Ä–±–æ—Ä–¥–µ. –í –ø—Ä–æ—Ç–∏–≤–Ω–æ–º —Å–ª—É—á–∞–µ –º—ã –±—É–¥–µ–º –≤—ã–Ω—É–∂–¥–µ–Ω—ã –Ω–µ –∑–∞—Å—á–∏—Ç–∞—Ç—å –∑–∞–¥–∞–Ω–∏–µ :( \n",
    "\n",
    "#### –ü—Ä–æ –¥–∞–Ω–Ω—ã–µ:\n",
    "–ö–∞–∂–¥–æ–µ —Ä–µ–≤—å—é —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ –¥–≤—É—Ö —Ç–µ–∫—Å—Ç–æ–≤: positive –∏ negative - –ø–ª—é—Å—ã –∏ –º–∏–Ω—É—Å—ã –æ—Ç–µ–ª—è. –í —Å—Ç–æ–ª–±—Ü–µ score –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –æ—Ü–µ–Ω–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è - –≤–µ—â–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ —á–∏—Å–ª–æ 0 –¥–æ 10. –í–∞–º –Ω—É–∂–Ω–æ –∏–∑–≤–ª–µ—á—å –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ —ç—Ç–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤ –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –ø–æ –Ω–∏–º –æ—Ü–µ–Ω–∫—É.\n",
    "\n",
    "–î–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ —Ç—Ä–µ–π–Ω –∏ —Ç–µ—Å—Ç.\n",
    "\n",
    "Good luck & have fun! üí™"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T6Ej16t1XHaM"
   },
   "source": [
    "#### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª—é–±—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∫—Ä–æ–º–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –æ—Ä–≥–∞–Ω–∏–∑–∞—Ç–æ—Ä–∞–º–∏ —Å—Ç—Ä–æ–≥–æ –∑–∞–ø—Ä–µ—â–µ–Ω–æ. –í –ø–æ—Å–ª–µ–¥–Ω–µ–π —á–∞—Å—Ç–∏ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –∏–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ `transformers`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "U4Gc4Go5XHaN"
   },
   "outputs": [],
   "source": [
    "PATH_TO_TRAIN_DATA = 'data/train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "6kJRM6ZUXHaO",
    "outputId": "e6ba4512-21c3-4dd8-a1d5-e270541cdc64"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00003c6036f30f590c0ac435efb8739b</td>\n",
       "      <td>There were issues with the wifi connection</td>\n",
       "      <td>No Positive</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00004d18f186bf2489590dc415876f73</td>\n",
       "      <td>TV not working</td>\n",
       "      <td>No Positive</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000cf900cbb8667fad33a717e9b1cf4</td>\n",
       "      <td>More pillows</td>\n",
       "      <td>Beautiful room Great location Lovely staff</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000df16edf19e7ad9dd8c5cd6f6925e</td>\n",
       "      <td>Very business</td>\n",
       "      <td>Location</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00025e1aa3ac32edb496db49e76bbd00</td>\n",
       "      <td>Rooms could do with a bit of a refurbishment ...</td>\n",
       "      <td>Nice breakfast handy for Victoria train stati...</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          review_id  \\\n",
       "0  00003c6036f30f590c0ac435efb8739b   \n",
       "1  00004d18f186bf2489590dc415876f73   \n",
       "2  0000cf900cbb8667fad33a717e9b1cf4   \n",
       "3  0000df16edf19e7ad9dd8c5cd6f6925e   \n",
       "4  00025e1aa3ac32edb496db49e76bbd00   \n",
       "\n",
       "                                            negative  \\\n",
       "0         There were issues with the wifi connection   \n",
       "1                                     TV not working   \n",
       "2                                       More pillows   \n",
       "3                                      Very business   \n",
       "4   Rooms could do with a bit of a refurbishment ...   \n",
       "\n",
       "                                            positive  score  \n",
       "0                                        No Positive    7.1  \n",
       "1                                        No Positive    7.5  \n",
       "2        Beautiful room Great location Lovely staff    10.0  \n",
       "3                                           Location    5.4  \n",
       "4   Nice breakfast handy for Victoria train stati...    6.7  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(PATH_TO_TRAIN_DATA)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bpLk8dXBXHaP"
   },
   "source": [
    "–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –º–æ–∂–µ—Ç —Å–∫–∞–∑—ã–≤–∞—Ç—å—Å—è –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–µ –≤–∞—à–µ–π –º–æ–¥–µ–ª–∏.\n",
    "–°–¥–µ–ª–∞–µ–º –Ω–µ–±–æ–ª—å—à–æ–π –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ —Ç–µ–∫—Å—Ç–æ–≤: —É–¥–∞–ª–∏–º –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è, –ø—Ä–∏–≤–µ–¥–µ–º –≤—Å–µ —Å–ª–æ–≤–∞ –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É. \n",
    "–û–¥–Ω–∞–∫–æ –º–æ–∂–Ω–æ –Ω–µ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞—Ç—å—Å—è —ç—Ç–∏–º –Ω–∞–±–æ—Ä–æ–º –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–π. –ü–æ–¥—É–º–∞–π—Ç–µ, —á—Ç–æ –µ—â–µ –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å —Å —Ç–µ–∫—Å—Ç–∞–º–∏, —á—Ç–æ–±—ã –ø–æ–º–æ—á—å –±—É–¥—É—â–∏–º –º–æ–¥–µ–ª—è–º? –î–æ–±–∞–≤—å—Ç–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥–ª–∏ –±—ã –ø–æ–º–æ—á—å –ø–æ –≤–∞—à–µ–º—É –º–Ω–µ–Ω–∏—é."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SfkhII5AXHaP"
   },
   "source": [
    "–¢–∞–∫–∂–µ –º—ã –¥–æ–±–∞–≤–∏–ª–∏ —Ä–∞–∑–±–∏–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤ –Ω–∞ —Ç–æ–∫–µ–Ω—ã. –¢–µ–ø–µ—Ä—å –∫–∞–∂–¥–∞—è —Å—Ç—Ä–æ–∫–∞-—Ä–µ–≤—å—é —Å—Ç–∞–ª–∞ –º–∞—Å—Å–∏–≤–æ–º —Ç–æ–∫–µ–Ω–æ–≤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "tv-gbEKGXHaQ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/alex/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/alex/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "def process_text(text):\n",
    "    # remove empty parts\n",
    "    text = text.replace('No Negative', '').replace('No Positive', '')\n",
    "    # tokenize\n",
    "    words = word_tokenize(text)\n",
    "    # remove all punctuation\n",
    "    words = [word.strip(string.punctuation) for word in words]\n",
    "    # remove stop words\n",
    "    words = [word for word in words if word not in stopwords.words('english')]\n",
    "    # stem words\n",
    "    stemmer = PorterStemmer()\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "    # remove small words\n",
    "    words = [word for word in words if len(word) > 1]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "-X1bXhROXHaQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 16 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize()\n",
    "\n",
    "df['negative'] = df['negative'].parallel_apply(process_text)\n",
    "df['positive'] = df['positive'].parallel_apply(process_text)\n",
    "df['review'] = df['positive'] + df['negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('data/processed_ipynb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_pickle('data/processed_ipynb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>score</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00003c6036f30f590c0ac435efb8739b</td>\n",
       "      <td>[there, issu, wifi, connect]</td>\n",
       "      <td>[]</td>\n",
       "      <td>7.1</td>\n",
       "      <td>[there, issu, wifi, connect]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00004d18f186bf2489590dc415876f73</td>\n",
       "      <td>[tv, work]</td>\n",
       "      <td>[]</td>\n",
       "      <td>7.5</td>\n",
       "      <td>[tv, work]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000cf900cbb8667fad33a717e9b1cf4</td>\n",
       "      <td>[more, pillow]</td>\n",
       "      <td>[beauti, room, great, locat, love, staff]</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[beauti, room, great, locat, love, staff, more...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000df16edf19e7ad9dd8c5cd6f6925e</td>\n",
       "      <td>[veri, busi]</td>\n",
       "      <td>[locat]</td>\n",
       "      <td>5.4</td>\n",
       "      <td>[locat, veri, busi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00025e1aa3ac32edb496db49e76bbd00</td>\n",
       "      <td>[room, could, bit, refurbish, could, corridor,...</td>\n",
       "      <td>[nice, breakfast, handi, victoria, train, stat...</td>\n",
       "      <td>6.7</td>\n",
       "      <td>[nice, breakfast, handi, victoria, train, stat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          review_id  \\\n",
       "0  00003c6036f30f590c0ac435efb8739b   \n",
       "1  00004d18f186bf2489590dc415876f73   \n",
       "2  0000cf900cbb8667fad33a717e9b1cf4   \n",
       "3  0000df16edf19e7ad9dd8c5cd6f6925e   \n",
       "4  00025e1aa3ac32edb496db49e76bbd00   \n",
       "\n",
       "                                            negative  \\\n",
       "0                       [there, issu, wifi, connect]   \n",
       "1                                         [tv, work]   \n",
       "2                                     [more, pillow]   \n",
       "3                                       [veri, busi]   \n",
       "4  [room, could, bit, refurbish, could, corridor,...   \n",
       "\n",
       "                                            positive  score  \\\n",
       "0                                                 []    7.1   \n",
       "1                                                 []    7.5   \n",
       "2          [beauti, room, great, locat, love, staff]   10.0   \n",
       "3                                            [locat]    5.4   \n",
       "4  [nice, breakfast, handi, victoria, train, stat...    6.7   \n",
       "\n",
       "                                              review  \n",
       "0                       [there, issu, wifi, connect]  \n",
       "1                                         [tv, work]  \n",
       "2  [beauti, room, great, locat, love, staff, more...  \n",
       "3                                [locat, veri, busi]  \n",
       "4  [nice, breakfast, handi, victoria, train, stat...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>score</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00003c6036f30f590c0ac435efb8739b</td>\n",
       "      <td>[there, issu, wifi, connect]</td>\n",
       "      <td>[]</td>\n",
       "      <td>7.1</td>\n",
       "      <td>[there, issu, wifi, connect]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00004d18f186bf2489590dc415876f73</td>\n",
       "      <td>[tv, work]</td>\n",
       "      <td>[]</td>\n",
       "      <td>7.5</td>\n",
       "      <td>[tv, work]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000cf900cbb8667fad33a717e9b1cf4</td>\n",
       "      <td>[more, pillow]</td>\n",
       "      <td>[beauti, room, great, locat, love, staff]</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[beauti, room, great, locat, love, staff, more...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000df16edf19e7ad9dd8c5cd6f6925e</td>\n",
       "      <td>[veri, busi]</td>\n",
       "      <td>[locat]</td>\n",
       "      <td>5.4</td>\n",
       "      <td>[locat, veri, busi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00025e1aa3ac32edb496db49e76bbd00</td>\n",
       "      <td>[room, could, bit, refurbish, could, corridor,...</td>\n",
       "      <td>[nice, breakfast, handi, victoria, train, stat...</td>\n",
       "      <td>6.7</td>\n",
       "      <td>[nice, breakfast, handi, victoria, train, stat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          review_id  \\\n",
       "0  00003c6036f30f590c0ac435efb8739b   \n",
       "1  00004d18f186bf2489590dc415876f73   \n",
       "2  0000cf900cbb8667fad33a717e9b1cf4   \n",
       "3  0000df16edf19e7ad9dd8c5cd6f6925e   \n",
       "4  00025e1aa3ac32edb496db49e76bbd00   \n",
       "\n",
       "                                            negative  \\\n",
       "0                       [there, issu, wifi, connect]   \n",
       "1                                         [tv, work]   \n",
       "2                                     [more, pillow]   \n",
       "3                                       [veri, busi]   \n",
       "4  [room, could, bit, refurbish, could, corridor,...   \n",
       "\n",
       "                                            positive  score  \\\n",
       "0                                                 []    7.1   \n",
       "1                                                 []    7.5   \n",
       "2          [beauti, room, great, locat, love, staff]   10.0   \n",
       "3                                            [locat]    5.4   \n",
       "4  [nice, breakfast, handi, victoria, train, stat...    6.7   \n",
       "\n",
       "                                              review  \n",
       "0                       [there, issu, wifi, connect]  \n",
       "1                                         [tv, work]  \n",
       "2  [beauti, room, great, locat, love, staff, more...  \n",
       "3                                [locat, veri, busi]  \n",
       "4  [nice, breakfast, handi, victoria, train, stat...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "MewBIvp9XHaQ"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df2.drop(columns=['review_id','score'])\n",
    "y = df2.score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1412) # <- –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41766</th>\n",
       "      <td>[room, tini, price, exhorbit, size, room]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[room, tini, price, exhorbit, size, room]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99660</th>\n",
       "      <td>[]</td>\n",
       "      <td>[excel, staff, hotel]</td>\n",
       "      <td>[excel, staff, hotel]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19507</th>\n",
       "      <td>[veri, facil, eg, coffe, shop, leisur, facil, ...</td>\n",
       "      <td>[the, staff, went, way, friendli, welcom]</td>\n",
       "      <td>[the, staff, went, way, friendli, welcom, veri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72103</th>\n",
       "      <td>[the, receptionist, desk, need, improv, lack, ...</td>\n",
       "      <td>[the, locat, superb, we, night, pari, and, mak...</td>\n",
       "      <td>[the, locat, superb, we, night, pari, and, mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69073</th>\n",
       "      <td>[park, option, well, solv]</td>\n",
       "      <td>[perfect, locat, valu, money]</td>\n",
       "      <td>[perfect, locat, valu, money, park, option, we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33144</th>\n",
       "      <td>[extrem, imperson, overrun, peopl, mill, around]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[extrem, imperson, overrun, peopl, mill, around]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65200</th>\n",
       "      <td>[couldn, find, dislik]</td>\n",
       "      <td>[veri, profession, staff, throughout, hotel, e...</td>\n",
       "      <td>[veri, profession, staff, throughout, hotel, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49810</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86805</th>\n",
       "      <td>[bed, bit, soft, fell, one, point, lot, charge...</td>\n",
       "      <td>[locat, staff, rooftop, pool]</td>\n",
       "      <td>[locat, staff, rooftop, pool, bed, bit, soft, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56070</th>\n",
       "      <td>[]</td>\n",
       "      <td>[though, min, walk, barcelona, sant, away, mad...</td>\n",
       "      <td>[though, min, walk, barcelona, sant, away, mad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75000 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                negative  \\\n",
       "41766          [room, tini, price, exhorbit, size, room]   \n",
       "99660                                                 []   \n",
       "19507  [veri, facil, eg, coffe, shop, leisur, facil, ...   \n",
       "72103  [the, receptionist, desk, need, improv, lack, ...   \n",
       "69073                         [park, option, well, solv]   \n",
       "...                                                  ...   \n",
       "33144   [extrem, imperson, overrun, peopl, mill, around]   \n",
       "65200                             [couldn, find, dislik]   \n",
       "49810                                                 []   \n",
       "86805  [bed, bit, soft, fell, one, point, lot, charge...   \n",
       "56070                                                 []   \n",
       "\n",
       "                                                positive  \\\n",
       "41766                                                 []   \n",
       "99660                              [excel, staff, hotel]   \n",
       "19507          [the, staff, went, way, friendli, welcom]   \n",
       "72103  [the, locat, superb, we, night, pari, and, mak...   \n",
       "69073                      [perfect, locat, valu, money]   \n",
       "...                                                  ...   \n",
       "33144                                                 []   \n",
       "65200  [veri, profession, staff, throughout, hotel, e...   \n",
       "49810                                                 []   \n",
       "86805                      [locat, staff, rooftop, pool]   \n",
       "56070  [though, min, walk, barcelona, sant, away, mad...   \n",
       "\n",
       "                                                  review  \n",
       "41766          [room, tini, price, exhorbit, size, room]  \n",
       "99660                              [excel, staff, hotel]  \n",
       "19507  [the, staff, went, way, friendli, welcom, veri...  \n",
       "72103  [the, locat, superb, we, night, pari, and, mak...  \n",
       "69073  [perfect, locat, valu, money, park, option, we...  \n",
       "...                                                  ...  \n",
       "33144   [extrem, imperson, overrun, peopl, mill, around]  \n",
       "65200  [veri, profession, staff, throughout, hotel, e...  \n",
       "49810                                                 []  \n",
       "86805  [locat, staff, rooftop, pool, bed, bit, soft, ...  \n",
       "56070  [though, min, walk, barcelona, sant, away, mad...  \n",
       "\n",
       "[75000 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3gu1EIc3XHaR"
   },
   "source": [
    "### –ß–∞—Å—Ç—å 1. 1 –±–∞–ª–ª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('X1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DM7ZD9gyXHaR"
   },
   "source": [
    "–û–±—É—á–∏—Ç–µ –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫—É—é –∏–ª–∏ –ª–∏–Ω–µ–π–Ω—É—é —Ä–µ–≥—Ä–µ—Å—Å–∏—é –Ω–∞ TF-IDF –≤–µ–∫—Ç–æ—Ä–∞—Ö —Ç–µ–∫—Å—Ç–æ–≤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "2x4yCjh8XHaR"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_absolute_error, make_scorer\n\u001b[1;32m      5\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[1;32m      6\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtfidf\u001b[39m\u001b[38;5;124m'\u001b[39m, ColumnTransformer([\n\u001b[1;32m      7\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtfidf_p\u001b[39m\u001b[38;5;124m'\u001b[39m, TfidfVectorizer(preprocessor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(x)), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpositive\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregression\u001b[39m\u001b[38;5;124m'\u001b[39m, Ridge())\n\u001b[1;32m     12\u001b[0m ])\n\u001b[0;32m---> 14\u001b[0m clf \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.10/envs/dl-3/lib/python3.9/site-packages/sklearn/pipeline.py:390\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m\"\"\"Fit the model.\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;124;03m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    389\u001b[0m fit_params_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_fit_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m--> 390\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.10/envs/dl-3/lib/python3.9/site-packages/sklearn/pipeline.py:348\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    346\u001b[0m     cloned_transformer \u001b[38;5;241m=\u001b[39m clone(transformer)\n\u001b[1;32m    347\u001b[0m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[0;32m--> 348\u001b[0m X, fitted_transformer \u001b[38;5;241m=\u001b[39m \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPipeline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_steps\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.10/envs/dl-3/lib/python3.9/site-packages/joblib/memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.10/envs/dl-3/lib/python3.9/site-packages/sklearn/pipeline.py:893\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m    892\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 893\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    894\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    895\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.10/envs/dl-3/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py:675\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_column_callables(X)\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_remainder(X)\n\u001b[0;32m--> 675\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_fit_transform_one\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result:\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fitted_transformers([])\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.10/envs/dl-3/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py:606\u001b[0m, in \u001b[0;36mColumnTransformer._fit_transform\u001b[0;34m(self, X, y, func, fitted, column_as_strings)\u001b[0m\n\u001b[1;32m    600\u001b[0m transformers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m    601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(\n\u001b[1;32m    602\u001b[0m         fitted\u001b[38;5;241m=\u001b[39mfitted, replace_strings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, column_as_strings\u001b[38;5;241m=\u001b[39mcolumn_as_strings\n\u001b[1;32m    603\u001b[0m     )\n\u001b[1;32m    604\u001b[0m )\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 606\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrans\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfitted\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrans\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m            \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m            \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mColumnTransformer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtransformers\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtransformers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.10/envs/dl-3/lib/python3.9/site-packages/joblib/parallel.py:1043\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1035\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1040\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1043\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1044\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.10/envs/dl-3/lib/python3.9/site-packages/joblib/parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.10/envs/dl-3/lib/python3.9/site-packages/joblib/parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    778\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 779\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.10/envs/dl-3/lib/python3.9/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.10/envs/dl-3/lib/python3.9/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.10/envs/dl-3/lib/python3.9/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.10/envs/dl-3/lib/python3.9/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.10/envs/dl-3/lib/python3.9/site-packages/sklearn/utils/fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.10/envs/dl-3/lib/python3.9/site-packages/sklearn/pipeline.py:893\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m    892\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 893\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    894\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    895\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.10/envs/dl-3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:2077\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   2058\u001b[0m \u001b[38;5;124;03m\"\"\"Learn vocabulary and idf, return document-term matrix.\u001b[39;00m\n\u001b[1;32m   2059\u001b[0m \n\u001b[1;32m   2060\u001b[0m \u001b[38;5;124;03mThis is equivalent to fit followed by transform, but more efficiently\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2074\u001b[0m \u001b[38;5;124;03m    Tf-idf-weighted document-term matrix.\u001b[39;00m\n\u001b[1;32m   2075\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2076\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params()\n\u001b[0;32m-> 2077\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2078\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[1;32m   2079\u001b[0m \u001b[38;5;66;03m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[1;32m   2080\u001b[0m \u001b[38;5;66;03m# we set copy to False\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.10/envs/dl-3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:1330\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1322\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1323\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1324\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1325\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1326\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1327\u001b[0m             )\n\u001b[1;32m   1328\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1330\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[1;32m   1333\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.10/envs/dl-3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:1220\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1218\u001b[0m     vocabulary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(vocabulary)\n\u001b[1;32m   1219\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m vocabulary:\n\u001b[0;32m-> 1220\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1221\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mempty vocabulary; perhaps the documents only contain stop words\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1222\u001b[0m         )\n\u001b[1;32m   1224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indptr[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39miinfo(np\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mmax:  \u001b[38;5;66;03m# = 2**31 - 1\u001b[39;00m\n\u001b[1;32m   1225\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _IS_32BIT:\n",
      "\u001b[0;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', ColumnTransformer([\n",
    "        ('tfidf_p', TfidfVectorizer(preprocessor=lambda x: ' '.join(x)), 'positive'),\n",
    "        ('tfidf_n', TfidfVectorizer(preprocessor=lambda x: ' '.join(x)), 'negative'),\n",
    "        ('tfidf', TfidfVectorizer(preprocessor=lambda x: ' '.join(x)), 'review'),\n",
    "    ])),\n",
    "    ('regression', Ridge())\n",
    "])\n",
    "\n",
    "clf = pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MAE: 0.6868365424851248\n",
      "Test MAE: 0.8301496175958935\n"
     ]
    }
   ],
   "source": [
    "print(f'Train MAE: {mean_absolute_error(y_train, clf.predict(X_train))}')\n",
    "print(f'Test MAE: {mean_absolute_error(y_test, clf.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0CufFcfHXhuo"
   },
   "source": [
    "–ü—Ä–µ–¥—Å–∫–∞–∂–∏—Ç–µ —ç—Ç–æ–π –º–æ–¥–µ–ª—å—é —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ [—Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏—è](https://www.kaggle.com/t/3e8fa6cec6d048bf8e93fb72e441d88c) –∏ —Å–¥–µ–ª–∞–π—Ç–µ —Å–∞–±–º–∏—Ç. –ö–∞–∫–æ–π —É –≤–∞—Å –ø–æ–ª—É—á–∏–ª—Å—è —Å–∫–æ—Ä? –ü—Ä–∏–∫—Ä–µ–ø–∏—Ç–µ —Å–∫—Ä–∏–Ω—à–æ—Ç –∏–∑ –∫—ç–≥–≥–ª–∞."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-4Zve40XHaS"
   },
   "source": [
    "### –ß–∞—Å—Ç—å 2. 2 –±–∞–ª–ª–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cYFL-5yFXHaS"
   },
   "source": [
    "–û–±—É—á–∏—Ç–µ –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫—É—é –∏–ª–∏ –ª–∏–Ω–µ–π–Ω—É—é —Ä–µ–≥—Ä–µ—Å—Å–∏—é –Ω–∞ —É—Å—Ä–µ–¥–Ω–µ–Ω–Ω—ã—Ö Word2Vec –≤–µ–∫—Ç–æ—Ä–∞—Ö. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jpcCEhBDXHaS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KWrIciGxXHaS"
   },
   "source": [
    "–£—Å—Ä–µ–¥–Ω—è—è w2v –≤–µ–∫—Ç–æ—Ä–∞, –º—ã –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ –∫–∞–∂–¥–æ–µ —Å–ª–æ–≤–æ –∏–º–µ–µ—Ç —Ä–∞–≤–Ω–æ—Ü–µ–Ω–Ω—ã–π –≤–∫–ª–∞–¥ –≤ —Å–º—ã—Å–ª –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –æ–¥–Ω–∞–∫–æ —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ —Å–æ–≤—Å–µ–º —Ç–∞–∫. –¢–µ–ø–µ—Ä—å –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –≤–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –¥—Ä—É–≥–æ–π –∫–æ–Ω—Ü–µ–ø—Ü–∏–µ–π –∏ –ø–µ—Ä–µ–≤–∑–≤–µ—Å–∏—Ç—å —Å–ª–æ–≤–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∏—Ç–æ–≥–æ–≤–æ–≥–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ —Ç–µ–∫—Å—Ç–∞. –í –∫–∞—á–µ—Å—Ç–≤–µ –≤–µ—Å–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ IDF (Inverse document frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mQSuuLP9XHaS"
   },
   "outputs": [],
   "source": [
    "def calc_idf(texts):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4s-6HQo0XHaT"
   },
   "source": [
    "–ü—Ä–æ–≤–µ–¥–∏—Ç–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã —Å —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å—é —ç–º–±–µ–¥–¥–∏–Ω–≥–∞. –î–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–∑ –¥–≤—É—Ö –º–µ—Ç–æ–¥–æ–≤ –ø–æ—Å—Ç—Ä–æ–π—Ç–µ –≥—Ä–∞—Ñ–∏–∫ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏ –æ—Ç —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞. \n",
    "\n",
    "#### –°–¥–µ–ª–∞–π—Ç–µ –≤—ã–≤–æ–¥—ã:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f29vizrmXHaT"
   },
   "source": [
    "–¢–µ–ø–µ—Ä—å –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –æ–±—É—á–∏—Ç—å –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫—É—é –∏–ª–∏ –ª–∏–Ω–µ–π–Ω—É—é —Ä–µ–≥—Ä–µ—Å—Å–∏—é –Ω–∞ –ª—é–±—ã—Ö –¥—Ä—É–≥–∏—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–∞—Ö —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ 300 –∏ —Å—Ä–∞–≤–Ω–∏—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ —Å Word2Vec.\n",
    "#### –í—ã–≤–æ–¥—ã:\n",
    "`<–í–ê–® –¢–ï–ö–°–¢ –ó–î–ï–°–¨>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9AjabHMsXXBu"
   },
   "source": [
    "–ü—Ä–µ–¥—Å–∫–∞–∂–∏—Ç–µ –≤–∞—à–µ–π –ª—É—á—à–µ–π –º–æ–¥–µ–ª—å—é –∏–∑ —ç—Ç–æ–≥–æ –∑–∞–¥–∞–Ω–∏—è —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ [—Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏—è](https://www.kaggle.com/t/3e8fa6cec6d048bf8e93fb72e441d88c) –∏ —Å–¥–µ–ª–∞–π—Ç–µ —Å–∞–±–º–∏—Ç. –ö–∞–∫–æ–π —É –≤–∞—Å –ø–æ–ª—É—á–∏–ª—Å—è —Å–∫–æ—Ä? –ü—Ä–∏–∫—Ä–µ–ø–∏—Ç–µ —Å–∫—Ä–∏–Ω—à–æ—Ç –∏–∑ –∫—ç–≥–≥–ª–∞."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EO5TZriLXHaT"
   },
   "source": [
    "### –ß–∞—Å—Ç—å 3. 4 –±–∞–ª–ª–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5RNngNdWXHaT"
   },
   "source": [
    "–¢–µ–ø–µ—Ä—å –¥–∞–≤–∞–π—Ç–µ –≤–æ—Å–ø–æ–ª—å–∑—É–µ–º—Å—è –±–æ–ª–µ–µ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–º–∏ –º–µ—Ç–æ–¥–∞–º–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –∫–æ—Ç–æ—Ä—ã–µ –º—ã –ø—Ä–æ—Ö–æ–¥–∏–ª–∏ –≤ –Ω–∞—à–µ–º –∫—É—Ä—Å–µ. –û–±—É—á–∏—Ç–µ RNN/Transformer –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–π –æ—Ü–µ–Ω–∫–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_8YdTedQXHaT"
   },
   "source": [
    "–ï—Å–ª–∏ –±—É–¥–µ—Ç–µ –æ–±—É—á–∞—Ç—å RNN, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –æ–≥—Ä–∞–Ω–∏—á–∏—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è. –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –æ—Ç–∑—ã–≤—ã –º–æ–≥—É—Ç –±—ã—Ç—å —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–µ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –æ—Å—Ç–∞–ª—å–Ω—ã—Ö.\n",
    "\n",
    "–ß—Ç–æ–±—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è DataLoader, –≤—Å–µ –µ–≥–æ —ç–ª–µ–º–µ–Ω—Ç—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –æ–¥–∏–Ω–∞–∫–æ–≤–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏. –î–ª—è —ç—Ç–æ–≥–æ –≤—ã –º–æ–∂–µ—Ç–µ –¥–æ–±–∞–≤–∏—Ç—å –Ω—É–ª–µ–≤–æ–π –ø–∞–¥–¥–∏–Ω–≥ –∫–æ –≤—Å–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º (—Å–º –ø—Ä–∏–º–µ—Ä pad_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "89Y9wsViXHaU"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dPOjSwwwXHaU"
   },
   "outputs": [],
   "source": [
    "WORDS = set()\n",
    "for sent in list(df['positive']):\n",
    "    for w in sent:\n",
    "        WORDS.add(w)\n",
    "        \n",
    "for sent in list(df['negative']):\n",
    "    for w in sent:\n",
    "        WORDS.add(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EMQ-cVxGXHaU"
   },
   "outputs": [],
   "source": [
    "int2word = dict(enumerate(tuple(WORDS)))\n",
    "word2int = {w: ii for ii, w in int2word.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GiKyqKIWXHaU"
   },
   "outputs": [],
   "source": [
    "MAX_LEN = max(max(df['positive'].apply(len)), max(df['negative'].apply(len)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "81o6S3_AXHaU",
    "outputId": "6ac4d30d-efc7-4324-eeda-d2950734813f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "399"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PQI2EGzbXHaV"
   },
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "train_pos_pad = pad_sequence([torch.as_tensor([word2int[w] for w in seq][:MAX_LEN]) for seq in df_train['positive']], \n",
    "                           batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "76PDJ4yTXHaV"
   },
   "outputs": [],
   "source": [
    "class ReviewsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        ## TODO\n",
    "        pass\n",
    "        \n",
    "    def __len__(self):\n",
    "        ## TODO\n",
    "        pass\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        ## TODO\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m8jxX9B2XHaV"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "\n",
    "train_dataset = ReviewsDataset(df_train)\n",
    "test_dataset = ReviewsDataset(df_test)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0f6EmAuJXHaV"
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 1\n",
    "\n",
    "for n in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    ## TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n3OeNQkoXHaW"
   },
   "source": [
    "### –ö–æ–Ω—Ç–µ—Å—Ç (–¥–æ 3 –±–∞–ª–ª–æ–≤)\n",
    "\n",
    "–ü–æ –∏—Ç–æ–≥–∞–º –≤—Å–µ—Ö –≤–∞—à–∏—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ –≤—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä—É—é —Å—á–∏—Ç–∞–µ—Ç–µ –ª—É—á—à–µ–π. –°–¥–µ–ª–∞–π—Ç–µ —Å–∞–±–º–∏—Ç –≤ –∫–æ–Ω—Ç–µ—Å—Ç. –í –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –≤–∞—à–µ–≥–æ —Å–∫–æ—Ä–∞ –Ω–∞ –ø—É–±–ª–∏—á–Ω–æ–º –ª–∏–¥–µ—Ä–±–æ—Ä–¥–µ, –º—ã –Ω–∞—á–∏—Å–ª–∏–º –≤–∞–º –±–∞–ª–ª—ã:\n",
    "\n",
    " - <0.76 - 3 –±–∞–ª–ª–∞\n",
    " - [0.76; 0.78) - 2 –±–∞–ª–ª–∞\n",
    " - [0.78; 0.8) - 1 –±–∞–ª–ª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jfORFaucXHaW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hw3_kaggle.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
